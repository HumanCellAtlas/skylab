{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pysam\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import natsort\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from collections import Counter\n",
    "import distance\n",
    "\n",
    "from typing import List, Set, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (from https://samtools.github.io/hts-specs/SAMv1.pdf)\n",
    "MASK_MULTI_SEG = 0x1\n",
    "MASK_PROPER = 0x2\n",
    "MASK_UNMAPPED = 0x4\n",
    "MASK_NEXT_TMPL_UNMAPPED = 0x8\n",
    "MASK_RC = 0x10\n",
    "MASK_NEXT_RC = 0x20\n",
    "MASK_FIRST_SEG = 0x40\n",
    "MASK_LAST_SEG = 0x80\n",
    "MASK_SA = 0x100\n",
    "MASK_FAIL = 0x200\n",
    "MASK_DUPL = 0x400\n",
    "MASK_SUPL = 0x800\n",
    "MASK_PRIMARY = 0x900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed analysis of discordant records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `samtools sort -n merged.bam` \n",
    "op_bam_file = './optimus/merged.ns.bam'\n",
    "\n",
    "# `samtools sort -n possorted_genome_bam.bam`\n",
    "cr_bam_file = './cell_ranger/cellranger.ns.bam'\n",
    "\n",
    "op_bam = pysam.AlignmentFile(op_bam_file)\n",
    "cr_bam = pysam.AlignmentFile(cr_bam_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_record_attributes = namedtuple('bam_record_attributes', 'contig, start, end, cigar, flag, name')\n",
    "bam_tags = namedtuple('bam_tags', 'CR, UR, CB')\n",
    "\n",
    "def alignments_grouped_by_read_name_generator(bam_file: pysam.libcalignmentfile.AlignmentFile):\n",
    "    \"\"\"Iterates through a read-name-sorted BAM file and groups all alignments of a read.\n",
    "    \n",
    "    Returns:\n",
    "        a tuple of read-name and a list of its alignments\n",
    "    \"\"\"\n",
    "    bam_file.reset()\n",
    "    for alignment in itertools.groupby(bam_file, key=lambda alignment: alignment.query_name):\n",
    "        read_name = alignment[0]\n",
    "        grouper = alignment[1]\n",
    "        alignments = []\n",
    "        try:\n",
    "            while True:\n",
    "                alignment = grouper.__next__()\n",
    "                alignments.append(alignment)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        yield read_name, alignments\n",
    "\n",
    "def get_barcode_from_record(rec, barcode_tag_key='CR'):\n",
    "    orig_barcode = None\n",
    "    try:\n",
    "        orig_barcode = rec.get_tag(barcode_tag_key)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # record \"-x\" (for CellRanger)\n",
    "    fixed_barcode = orig_barcode.split('-')[0]\n",
    "    \n",
    "    return fixed_barcode\n",
    "\n",
    "def get_record_attributes(recs: List[pysam.AlignedSegment]) -> List[bam_record_attributes]:\n",
    "    return [bam_record_attributes(\n",
    "        contig=rec.reference_name,\n",
    "        start=rec.reference_start,\n",
    "        end=rec.reference_end,\n",
    "        cigar=rec.cigarstring,\n",
    "        flag=rec.flag,\n",
    "        name=rec.query_name) for rec in recs]\n",
    "\n",
    "def get_record_tags(recs: List[pysam.AlignedSegment]) -> List[bam_tags]:\n",
    "    return [bam_tags(\n",
    "        CR=get_barcode_from_record(rec, 'CR'),\n",
    "        UR=get_barcode_from_record(rec, 'UR'),\n",
    "        CB=get_barcode_from_record(rec, 'CB')) for rec in recs]\n",
    "\n",
    "def get_sorted_attributes_tags_list(attr_list, tags_list):\n",
    "    # sort by alignment\n",
    "    sorted_index_attr_list = sorted(\n",
    "        enumerate(attr_list),\n",
    "        key=lambda entry: (entry[1].contig, entry[1].start, entry[1].end, entry[1].cigar))\n",
    "    sort_index = [entry[0] for entry in sorted_index_attr_list]\n",
    "    sorted_attr_list = [entry[1] for entry in sorted_index_attr_list]\n",
    "    sorted_tags_list = [tags_list[j] for j in sort_index]\n",
    "    return sorted_attr_list, sorted_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate generators for alignements grouped by read-name\n",
    "op_grouped_records_gen = alignments_grouped_by_read_name_generator(op_bam)\n",
    "cr_grouped_records_gen = alignments_grouped_by_read_name_generator(cr_bam)\n",
    "\n",
    "# master list of parsed records (for further analysis)\n",
    "op_master_rec_attr_list = list()\n",
    "cr_master_rec_attr_list = list()\n",
    "op_master_rec_tags_list = list()\n",
    "cr_master_rec_tags_list = list()\n",
    "\n",
    "# indices of discordant records\n",
    "discordant_alignment_indices = list()\n",
    "discordant_flag_indices = list()\n",
    "discordant_CR_indices = list()\n",
    "discordant_UR_indices = list()\n",
    "discordant_CB_indices = list()\n",
    "\n",
    "read_index = 0\n",
    "for (op_read_name, op_recs), (cr_read_name, cr_recs) in zip(op_grouped_records_gen, cr_grouped_records_gen):\n",
    "    assert op_read_name == cr_read_name, \"Different read names\"\n",
    "    assert len(op_recs) == len(cr_recs), \"Different number of alignment positions\"\n",
    "    \n",
    "    op_rec_attr_list = get_record_attributes(op_recs)\n",
    "    cr_rec_attr_list = get_record_attributes(cr_recs)\n",
    "    op_tags_list = get_record_tags(op_recs)\n",
    "    cr_tags_list = get_record_tags(cr_recs)\n",
    "    \n",
    "    # sort by alignment position\n",
    "    sorted_op_rec_attr_list, sorted_op_tags_list = get_sorted_attributes_tags_list(\n",
    "        op_rec_attr_list, op_tags_list)\n",
    "    sorted_cr_rec_attr_list, sorted_cr_tags_list = get_sorted_attributes_tags_list(\n",
    "        cr_rec_attr_list, cr_tags_list)\n",
    "    \n",
    "    # add to the master list\n",
    "    op_master_rec_attr_list.append(sorted_op_rec_attr_list)\n",
    "    cr_master_rec_attr_list.append(sorted_cr_rec_attr_list)\n",
    "    op_master_rec_tags_list.append(sorted_op_tags_list)\n",
    "    cr_master_rec_tags_list.append(sorted_cr_tags_list)\n",
    "    \n",
    "    # discordant records\n",
    "    op_alignments = [(attr.contig, attr.start, attr.end, attr.cigar) for attr in sorted_op_rec_attr_list]\n",
    "    cr_alignments = [(attr.contig, attr.start, attr.end, attr.cigar) for attr in sorted_cr_rec_attr_list]\n",
    "    if op_alignments != cr_alignments:\n",
    "        discordant_alignment_indices.append(read_index)\n",
    "\n",
    "    op_flags = [attr.flag for attr in sorted_op_rec_attr_list]\n",
    "    cr_flags = [attr.flag for attr in sorted_cr_rec_attr_list]\n",
    "    if op_flags != cr_flags:\n",
    "        discordant_flag_indices.append(read_index)\n",
    "\n",
    "    op_CR = [tags.CR for tags in sorted_op_tags_list]\n",
    "    cr_CR = [tags.CR for tags in sorted_cr_tags_list]\n",
    "    if op_CR != cr_CR:\n",
    "        discordant_CR_indices.append(read_index)\n",
    "\n",
    "    op_UR = [tags.UR for tags in sorted_op_tags_list]\n",
    "    cr_UR = [tags.UR for tags in sorted_cr_tags_list]\n",
    "    if op_UR != cr_UR:\n",
    "        discordant_UR_indices.append(read_index)\n",
    "\n",
    "    op_CB = [tags.CB for tags in sorted_op_tags_list]\n",
    "    cr_CB = [tags.CB for tags in sorted_cr_tags_list]\n",
    "    if op_CB != cr_CB:\n",
    "        discordant_CB_indices.append(read_index)\n",
    "\n",
    "    # increment index\n",
    "    read_index += 1\n",
    "    \n",
    "num_total_records = read_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of reads: 1036880\n",
      "number of reads with discordant alignments: 0\n",
      "number of reads with discordant flags: 543424, fraction = 0.5241\n",
      "number of reads with discordant CR: 0, fraction = 0.0000\n",
      "number of reads with discordant UR: 0, fraction = 0.0000\n",
      "number of reads with discordant CB: 2764, fraction = 0.0027\n"
     ]
    }
   ],
   "source": [
    "print(f'total number of reads: {num_total_records}')\n",
    "print(f'number of reads with discordant alignments: {len(discordant_alignment_indices)}')\n",
    "print(f'number of reads with discordant flags: {len(discordant_flag_indices)}, \\\n",
    "fraction = {len(discordant_flag_indices)/num_total_records:.4f}')\n",
    "print(f'number of reads with discordant CR: {len(discordant_CR_indices)}, \\\n",
    "fraction = {len(discordant_CR_indices)/num_total_records:.4f}')\n",
    "print(f'number of reads with discordant UR: {len(discordant_UR_indices)}, \\\n",
    "fraction = {len(discordant_UR_indices)/num_total_records:.4f}')\n",
    "print(f'number of reads with discordant CB: {len(discordant_CB_indices)}, \\\n",
    "fraction = {len(discordant_CB_indices)/num_total_records:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads with discordant CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimus reads missing CB: 0, fraction = 0.0000\n",
      "CellRanger reads missing CB: 1271, fraction = 0.0012\n",
      "Discordant CB between CellRanger and Optimus: 1493, fraction = 0.0014\n",
      "Distribution of (CB, CR) Hamming distance for Optimus reads: Counter({1: 1493})\n",
      "Distribution of (CB, CR) Hamming distance for CellRanger reads: Counter({1: 1493})\n",
      "Distribution of (CB, CB) Hamming distance between Optimus and CellRanger reads: Counter({2: 1493})\n",
      "Number of unique implicated CRs: 1107\n"
     ]
    }
   ],
   "source": [
    "op_missing_CB = 0\n",
    "cr_missing_CB = 0\n",
    "\n",
    "# list of tuples of d(op_CB, op_CR), d(cr_CB, cr_CR), d(op_CB, cr_CB)\n",
    "hamming_distance_tuples = list()\n",
    "implicated_CR_set = set()\n",
    "\n",
    "for idx in discordant_CB_indices:\n",
    "    op_CB_list = list(set(tags.CB for tags in op_master_rec_tags_list[idx]))\n",
    "    cr_CB_list = list(set(tags.CB for tags in cr_master_rec_tags_list[idx]))\n",
    "    assert len(op_CB_list) == 1\n",
    "    assert len(cr_CB_list) == 1\n",
    "    op_CB = op_CB_list[0]\n",
    "    cr_CB = cr_CB_list[0]\n",
    "    \n",
    "    if op_CB is None:\n",
    "        op_missing_CB += 1\n",
    "        continue\n",
    "        \n",
    "    if cr_CB is None:\n",
    "        cr_missing_CB += 1\n",
    "        continue\n",
    "\n",
    "    op_CR = op_master_rec_tags_list[idx][0].CR\n",
    "    cr_CR = cr_master_rec_tags_list[idx][0].CR\n",
    "    \n",
    "    assert op_CR == cr_CR\n",
    "    \n",
    "    implicated_CR_set.add(op_CR)\n",
    "    \n",
    "    op_CB_CR_hamming_dist = distance.hamming(op_CB, op_CR)\n",
    "    cr_CB_CR_hamming_dist = distance.hamming(cr_CB, cr_CR)    \n",
    "    op_cr_CB_CB_hamming_dist = distance.hamming(op_CB, cr_CB)\n",
    "    \n",
    "    hamming_distance_tuples.append((op_CB_CR_hamming_dist, cr_CB_CR_hamming_dist, op_cr_CB_CB_hamming_dist))\n",
    "    \n",
    "op_CB_CR_hamming_dist_hist = Counter([entry[0] for entry in hamming_distance_tuples])\n",
    "cr_CB_CR_hamming_dist_hist = Counter([entry[1] for entry in hamming_distance_tuples])\n",
    "op_cr_CB_CB_hamming_dist_hist = Counter([entry[2] for entry in hamming_distance_tuples])\n",
    "\n",
    "print(f'Optimus reads missing CB: {op_missing_CB}, fraction = {op_missing_CB/num_total_records:.4f}')\n",
    "print(f'CellRanger reads missing CB: {cr_missing_CB}, fraction = {cr_missing_CB/num_total_records:.4f}')\n",
    "print(f'Discordant CB between CellRanger and Optimus: \\\n",
    "{len(hamming_distance_tuples)}, fraction = {len(hamming_distance_tuples)/num_total_records:.4f}')\n",
    "print(f'Distribution of (CB, CR) Hamming distance for Optimus reads: \\\n",
    "{op_CB_CR_hamming_dist_hist}')\n",
    "print(f'Distribution of (CB, CR) Hamming distance for CellRanger reads: \\\n",
    "{cr_CB_CR_hamming_dist_hist}')\n",
    "print(f'Distribution of (CB, CB) Hamming distance between Optimus and CellRanger reads: \\\n",
    "{op_cr_CB_CB_hamming_dist_hist}')\n",
    "print(f'Number of unique implicated CRs: {len(implicated_CR_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "- All Optimus reads have CB tags\n",
    "- Some CellRanger reads do not have CB tags\n",
    "- Both Optimis and CellRanger only correct barcodes within 1HD from the whitelist\n",
    "- Optimus and CellRanger correct barcode errors in _different ways_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads with discordant flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlagSummaryStatistics:\n",
    "    def __init__(self):\n",
    "        self.num_multi_seg = 0\n",
    "        self.num_proper = 0\n",
    "        self.num_umapped = 0\n",
    "        self.num_next_templ_unmapped = 0\n",
    "        self.num_rc = 0\n",
    "        self.num_next_rc = 0\n",
    "        self.num_first_seg = 0\n",
    "        self.num_last_seg = 0\n",
    "        self.num_sa = 0\n",
    "        self.num_fail = 0\n",
    "        self.num_dupl = 0\n",
    "        self.num_supl = 0\n",
    "    \n",
    "    def _add_flag_to_summary(self, flag):\n",
    "        self.num_multi_seg += (flag & MASK_MULTI_SEG) >> 0\n",
    "        self.num_proper += (flag & MASK_PROPER) >> 1\n",
    "        self.num_umapped += (flag & MASK_UNMAPPED) >> 2\n",
    "        self.num_next_templ_unmapped += (flag & MASK_NEXT_TMPL_UNMAPPED) >> 3\n",
    "        self.num_rc += (flag & MASK_RC) >> 4\n",
    "        self.num_next_rc += (flag & MASK_NEXT_RC) >> 5\n",
    "        self.num_first_seg += (flag & MASK_FIRST_SEG) >> 6\n",
    "        self.num_last_seg += (flag & MASK_LAST_SEG) >> 7\n",
    "        self.num_sa += (flag & MASK_SA) >> 8\n",
    "        self.num_fail += (flag & MASK_FAIL) >> 9\n",
    "        self.num_dupl += (flag & MASK_DUPL) >> 10\n",
    "        self.num_supl += (flag & MASK_SUPL) >> 11\n",
    "        \n",
    "    @staticmethod\n",
    "    def _combine_flags(flags, op='or', primary_only=False):\n",
    "        if primary_only:\n",
    "            try:\n",
    "                filtered_flags = [flag for flag in flags if flag & MASK_PRIMARY == 0]\n",
    "            except:\n",
    "                raise Exception(\"No primary alignment is available\")\n",
    "        else:\n",
    "            filtered_flags = flags\n",
    "            \n",
    "        combined_flag = 0\n",
    "        if op == 'or':\n",
    "            for flag in filtered_flags:\n",
    "                combined_flag |= flag\n",
    "        elif op == 'xor':\n",
    "            for flag in filtered_flags:\n",
    "                combined_flag ^= flag\n",
    "        elif op == 'and':\n",
    "            for flag in filtered_flags:\n",
    "                combined_flag &= flag\n",
    "        else:\n",
    "            raise Exception(f'Unknown bitwise operation {op}')\n",
    "\n",
    "        return combined_flag\n",
    "    \n",
    "    def process_single(self, flags, op='or', primary_only=False):\n",
    "        \"\"\"Takes an iterable of binary flags, combines them according to a given bitwise operation, and updates\n",
    "        the summary statistics.\"\"\"\n",
    "        combined_flag = self._combine_flags(flags, op, primary_only)\n",
    "        self._add_flag_to_summary(combined_flag)\n",
    "\n",
    "    def process_difference(self, first_flags, second_flags, joint_op='xor', primary_only=False):\n",
    "        first_combined_flag = self._combine_flags(first_flags, op='or', primary_only=primary_only)\n",
    "        second_combined_flag = self._combine_flags(second_flags, op='or', primary_only=primary_only)\n",
    "        if joint_op == 'xor':\n",
    "            self._add_flag_to_summary(first_combined_flag ^ second_combined_flag)\n",
    "        elif joint_op == 'and':\n",
    "            self._add_flag_to_summary(first_combined_flag & second_combined_flag)\n",
    "        else:\n",
    "            raise Exception(f'Unknown joint operation {joint_op}')\n",
    "            \n",
    "    def print_summary(self):\n",
    "        print(f'num_multi_seg: {self.num_multi_seg}')\n",
    "        print(f'num_proper: {self.num_proper}')\n",
    "        print(f'num_umapped: {self.num_umapped}')\n",
    "        print(f'num_next_templ_unmapped: {self.num_next_templ_unmapped}')\n",
    "        print(f'num_rc: {self.num_rc}')\n",
    "        print(f'num_next_rc: {self.num_next_rc}')\n",
    "        print(f'num_first_seg: {self.num_first_seg}')\n",
    "        print(f'num_last_seg: {self.num_last_seg}')\n",
    "        print(f'num_sa: {self.num_sa}')\n",
    "        print(f'num_fail: {self.num_fail}')\n",
    "        print(f'num_dupl: {self.num_dupl}')\n",
    "        print(f'num_supl: {self.num_supl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_multiple_primary = 0\n",
    "cr_multiple_primary = 0\n",
    "\n",
    "for idx in discordant_flag_indices:\n",
    "    op_flags = [attr.flag for attr in op_master_rec_attr_list[idx]]\n",
    "    cr_flags = [attr.flag for attr in cr_master_rec_attr_list[idx]]\n",
    "    \n",
    "    # reads with more than one primary alignment (!)\n",
    "    # according to SAM specs, each read should have only one primary alignment\n",
    "    # Note: the issue stems from the synthetic data -- will follow up; for now, let us\n",
    "    # ignore such reads\n",
    "    op_recs_multiple_primary = sum(flag & MASK_PRIMARY == 0 for flag in op_flags) > 1\n",
    "    cr_recs_multiple_primary = sum(flag & MASK_PRIMARY == 0 for flag in cr_flags) > 1\n",
    "    op_multiple_primary += op_recs_multiple_primary\n",
    "    cr_multiple_primary += cr_recs_multiple_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_flag_summary_stats = FlagSummaryStatistics()\n",
    "cr_flag_summary_stats = FlagSummaryStatistics()\n",
    "\n",
    "for idx in discordant_flag_indices:\n",
    "    op_flags = [attr.flag for attr in op_master_rec_attr_list[idx]]\n",
    "    cr_flags = [attr.flag for attr in cr_master_rec_attr_list[idx]]\n",
    "\n",
    "    op_flag_summary_stats.process_single(op_flags, primary_only=False)\n",
    "    cr_flag_summary_stats.process_single(cr_flags, primary_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_primary_only_flag_summary_stats = FlagSummaryStatistics()\n",
    "cr_primary_only_flag_summary_stats = FlagSummaryStatistics()\n",
    "\n",
    "for idx in discordant_flag_indices:\n",
    "    op_flags = [attr.flag for attr in op_master_rec_attr_list[idx]]\n",
    "    cr_flags = [attr.flag for attr in cr_master_rec_attr_list[idx]]\n",
    "\n",
    "    op_primary_only_flag_summary_stats.process_single(op_flags, primary_only=True)\n",
    "    cr_primary_only_flag_summary_stats.process_single(cr_flags, primary_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_only_flag_xor_summary_stats = FlagSummaryStatistics()\n",
    "primary_only_flag_and_summary_stats = FlagSummaryStatistics()\n",
    "\n",
    "for idx in discordant_flag_indices:\n",
    "    op_flags = [attr.flag for attr in op_master_rec_attr_list[idx]]\n",
    "    cr_flags = [attr.flag for attr in cr_master_rec_attr_list[idx]]\n",
    "\n",
    "    primary_only_flag_xor_summary_stats.process_difference(\n",
    "        op_flags, cr_flags, primary_only=True, joint_op='xor')\n",
    "\n",
    "    primary_only_flag_and_summary_stats.process_difference(\n",
    "        op_flags, cr_flags, primary_only=True, joint_op='and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Optimus reads with multiple primary alignments: 72528, fraction = 0.0699\n",
      "Number of CellRanger reads with multiple primary alignments: 72262, fraction = 0.0697\n",
      "\n",
      "Optimus (primary only):\n",
      "num_multi_seg: 0\n",
      "num_proper: 0\n",
      "num_umapped: 0\n",
      "num_next_templ_unmapped: 0\n",
      "num_rc: 61348\n",
      "num_next_rc: 0\n",
      "num_first_seg: 0\n",
      "num_last_seg: 0\n",
      "num_sa: 0\n",
      "num_fail: 0\n",
      "num_dupl: 185600\n",
      "num_supl: 0\n",
      "\n",
      "CellRanger (primary only):\n",
      "num_multi_seg: 0\n",
      "num_proper: 0\n",
      "num_umapped: 0\n",
      "num_next_templ_unmapped: 0\n",
      "num_rc: 64645\n",
      "num_next_rc: 0\n",
      "num_first_seg: 0\n",
      "num_last_seg: 0\n",
      "num_sa: 0\n",
      "num_fail: 0\n",
      "num_dupl: 356877\n",
      "num_supl: 0\n",
      "\n",
      "joint XOR (primary only):\n",
      "num_multi_seg: 0\n",
      "num_proper: 0\n",
      "num_umapped: 0\n",
      "num_next_templ_unmapped: 0\n",
      "num_rc: 8413\n",
      "num_next_rc: 0\n",
      "num_first_seg: 0\n",
      "num_last_seg: 0\n",
      "num_sa: 0\n",
      "num_fail: 0\n",
      "num_dupl: 446777\n",
      "num_supl: 0\n",
      "\n",
      "joint AND (primary only):\n",
      "num_multi_seg: 0\n",
      "num_proper: 0\n",
      "num_umapped: 0\n",
      "num_next_templ_unmapped: 0\n",
      "num_rc: 58790\n",
      "num_next_rc: 0\n",
      "num_first_seg: 0\n",
      "num_last_seg: 0\n",
      "num_sa: 0\n",
      "num_fail: 0\n",
      "num_dupl: 47850\n",
      "num_supl: 0\n",
      "\n",
      "Optimus (all):\n",
      "num_multi_seg: 0\n",
      "num_proper: 0\n",
      "num_umapped: 0\n",
      "num_next_templ_unmapped: 0\n",
      "num_rc: 111207\n",
      "num_next_rc: 0\n",
      "num_first_seg: 0\n",
      "num_last_seg: 0\n",
      "num_sa: 541479\n",
      "num_fail: 0\n",
      "num_dupl: 185600\n",
      "num_supl: 0\n",
      "\n",
      "CellRanger (all):\n",
      "num_multi_seg: 0\n",
      "num_proper: 0\n",
      "num_umapped: 0\n",
      "num_next_templ_unmapped: 0\n",
      "num_rc: 111207\n",
      "num_next_rc: 0\n",
      "num_first_seg: 0\n",
      "num_last_seg: 0\n",
      "num_sa: 541479\n",
      "num_fail: 0\n",
      "num_dupl: 356877\n",
      "num_supl: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Optimus reads with multiple primary alignments: \\\n",
    "{op_multiple_primary}, fraction = {op_multiple_primary/num_total_records:.4f}')\n",
    "print(f'Number of CellRanger reads with multiple primary alignments: \\\n",
    "{cr_multiple_primary}, fraction = {cr_multiple_primary/num_total_records:.4f}')\n",
    "print()\n",
    "\n",
    "print('Optimus (primary only):')\n",
    "op_primary_only_flag_summary_stats.print_summary()\n",
    "print()\n",
    "\n",
    "print('CellRanger (primary only):')\n",
    "cr_primary_only_flag_summary_stats.print_summary()\n",
    "print()\n",
    "\n",
    "print('joint XOR (primary only):')\n",
    "primary_only_flag_xor_summary_stats.print_summary()\n",
    "print()\n",
    "\n",
    "print('joint AND (primary only):')\n",
    "primary_only_flag_and_summary_stats.print_summary()\n",
    "print()\n",
    "\n",
    "print('Optimus (all):')\n",
    "op_flag_summary_stats.print_summary()\n",
    "print()\n",
    "\n",
    "print('CellRanger (all):')\n",
    "cr_flag_summary_stats.print_summary()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "- There are about ~ 70k identical raw reads in the synthetic data and they need to be removed\n",
    "- For primary alignments with discordant flags, 47850 reads are marked as duplicate by both Optimus and CellRanger\n",
    "  whereas 446777 reads (about half of all reads) are marked duplicate differently\n",
    "- CellRanger marks more primary alignments as duplicate (356877 vs 185600), however, this does not necessary\n",
    "  imply more molecules.\n",
    "- It looks like `sctools` does not use the duplicate flag at all; `MarkDuplicates` only _marks_ duplicates. It does not remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_primary = 0\n",
    "for record in pysam.AlignmentFile(\"./optimus/cell-sorted.bam\"):\n",
    "    if (record.flag & MASK_PRIMARY) == 0 and record.mapping_quality == 255:\n",
    "        num_primary += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11833"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_primary = 0\n",
    "for record in pysam.AlignmentFile(\"./cell_ranger/possorted_genome_bam.bam\"):\n",
    "    if (record.flag & MASK_PRIMARY) == 0 and record.mapping_quality == 255:\n",
    "        num_primary += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760809"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_primary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "-- CellRanger definitely fiddles with flags in non-standard ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brute-force expression matrix calculator\n",
    "\n",
    "The idea is to mimick CellRanger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sctools import gtf\n",
    "from typing import List, Dict, Tuple, Set\n",
    "from scipy import sparse as sp\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_n_GE_UB_CB_bam_file = './optimus/sorted_n_GE_UB_CB.bam'\n",
    "annotation_file = './references/cellranger.gtf'\n",
    "gene_name_tag = 'GE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_name_to_index: Dict[str, int] = {}\n",
    "gtf_reader = gtf.Reader(annotation_file)\n",
    "\n",
    "# map the gene from reach record to an index in the sparse matrix\n",
    "for gene_index, record in enumerate(gtf_reader.filter(retain_types=['gene'])):\n",
    "    gene_name = record.get_attribute('gene_name')\n",
    "    if gene_name is None:\n",
    "        raise ValueError(\n",
    "            'malformed GTF file detected. Record is of type gene but does not have a '\n",
    "            '\"gene_name\" field: %s' % repr(record))\n",
    "    gene_name_to_index[gene_name] = gene_index\n",
    "\n",
    "n_genes = len(gene_name_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignments_grouped_by_query_name_generator(bam_path: pysam.libcalignmentfile.AlignmentFile,\n",
    "                                               cell_barcode_tag: str,\n",
    "                                               molecule_barcode_tag: str):\n",
    "    \"\"\"Iterates through a query-name-sorted BAM file and groups all alignments of a read.\n",
    "    \n",
    "    Returns:\n",
    "        a tuple of read-name and a list of its alignments\n",
    "    \"\"\"\n",
    "    with pysam.AlignmentFile(bam_path, 'rb') as bam_file:\n",
    "        for alignment in itertools.groupby(bam_file, key=lambda alignment: alignment.query_name):\n",
    "            query_name = alignment[0]\n",
    "            grouper = alignment[1]\n",
    "            alignments = []\n",
    "            try:\n",
    "                while True:\n",
    "                    alignment = grouper.__next__()\n",
    "                    alignments.append(alignment)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "\n",
    "            cell_barcode = None\n",
    "            try:\n",
    "                cell_barcode = alignments[0].get_tag(cell_barcode_tag)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            molecule_barcode = None\n",
    "            try:\n",
    "                molecule_barcode = alignments[0].get_tag(molecule_barcode_tag)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            yield query_name, cell_barcode, molecule_barcode, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_barcode_tag = 'CB'\n",
    "molecule_barcode_tag = 'UB'\n",
    "gene_name_tag = 'GE'\n",
    "\n",
    "# keep track of the observed triples (cell_barcode, molecule_barcode, gene_name) in a hash set\n",
    "observed_cell_molecule_gene_set: Set[Tuple[str, str, str]] = set()\n",
    "    \n",
    "# COO sparse matrix entries\n",
    "data: List[int] = []\n",
    "cell_indices: List[int] = []\n",
    "gene_indices: List[int] = []\n",
    "    \n",
    "# track which cells we've seen, and what the current cell number is\n",
    "n_cells = 0\n",
    "cell_barcode_to_index: Dict[str, int] = {}\n",
    "\n",
    "grouped_records_generator = alignments_grouped_by_query_name_generator(\n",
    "    sorted_n_GE_UB_CB_bam_file, cell_barcode_tag, molecule_barcode_tag)\n",
    "\n",
    "for query_name, cell_barcode, molecule_barcode, alignments in grouped_records_generator:\n",
    "    \n",
    "    if cell_barcode is None or molecule_barcode is None: # only keep queries w/ well-formed UMIs\n",
    "        continue\n",
    "    \n",
    "    if len(alignments) == 1:\n",
    "        primary_alignment = alignments[0]\n",
    "        if primary_alignment.has_tag(gene_name_tag):\n",
    "            gene_name = primary_alignment.get_tag(gene_name_tag)\n",
    "        else:\n",
    "            continue # drop query\n",
    "    else: # multi-map\n",
    "        implicated_gene_names: Set[str] = set()\n",
    "        for alignment in alignments:\n",
    "            if alignment.has_tag(gene_name_tag):\n",
    "                implicated_gene_names.add(alignment.get_tag(gene_name_tag))\n",
    "        if len(implicated_gene_names) == 1: # only one gene\n",
    "            gene_name = implicated_gene_names.__iter__().__next__()\n",
    "        else:\n",
    "            continue # drop query\n",
    "    \n",
    "    if (cell_barcode, molecule_barcode, gene_name) in observed_cell_molecule_gene_set:\n",
    "        continue # optical/PCR duplicate -> drop query\n",
    "    else:\n",
    "        observed_cell_molecule_gene_set.add((cell_barcode, molecule_barcode, gene_name))\n",
    "    \n",
    "    # find the indices that this molecule should correspond to\n",
    "    gene_index = gene_name_to_index[gene_name]\n",
    "\n",
    "    # if we've seen this cell before, get its index, else set it\n",
    "    try:\n",
    "        cell_index = cell_barcode_to_index[cell_barcode]\n",
    "    except KeyError:\n",
    "        cell_index = n_cells\n",
    "        cell_barcode_to_index[cell_barcode] = n_cells\n",
    "        n_cells += 1\n",
    "        \n",
    "    # record the molecule data\n",
    "    data.append(1)  # one count of this molecule\n",
    "    cell_indices.append(cell_index)\n",
    "    gene_indices.append(gene_index)\n",
    "    \n",
    "# convert into coo_matrix\n",
    "coordinate_matrix = sp.coo_matrix((data, (cell_indices, gene_indices)),\n",
    "    shape=(n_cells, n_genes), dtype=np.uint32)\n",
    "\n",
    "# convert into csr matrix and return\n",
    "col_index = np.asarray([k for k, v in sorted(gene_name_to_index.items(), key=operator.itemgetter(1))])\n",
    "row_index = np.asarray([k for k, v in sorted(cell_barcode_to_index.items(), key=operator.itemgetter(1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimus total counts: 261204\n"
     ]
    }
   ],
   "source": [
    "print(f'optimus total counts: {np.sum(coordinate_matrix)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sctools\n",
    "import collections\n",
    "import tables\n",
    "import scipy.sparse as sp_sparse\n",
    "\n",
    "GeneBCMatrix = collections.namedtuple('GeneBCMatrix', ['gene_ids', 'gene_names', 'barcodes', 'matrix'])\n",
    " \n",
    "def get_matrix_from_h5(filename, genome):\n",
    "    with tables.open_file(filename, 'r') as f:\n",
    "        try:\n",
    "            group = f.get_node(f.root, genome)\n",
    "        except tables.NoSuchNodeError:\n",
    "            print(\"That genome does not exist in this file.\")\n",
    "            return None\n",
    "        gene_ids = getattr(group, 'genes').read()\n",
    "        gene_names = getattr(group, 'gene_names').read()\n",
    "        barcodes = getattr(group, 'barcodes').read()\n",
    "        data = getattr(group, 'data').read()\n",
    "        indices = getattr(group, 'indices').read()\n",
    "        indptr = getattr(group, 'indptr').read()\n",
    "        shape = getattr(group, 'shape').read()\n",
    "        matrix = sp_sparse.csc_matrix((data, indices, indptr), shape=shape)\n",
    "        return GeneBCMatrix(gene_ids, gene_names, barcodes, matrix)\n",
    " \n",
    "filtered_matrix_h5 = \"cell_ranger/raw_gene_bc_matrices_h5.h5\"\n",
    "genome = \"GRCh38\"\n",
    "cr_cm = get_matrix_from_h5(filtered_matrix_h5, genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell ranger total counts: 246700\n"
     ]
    }
   ],
   "source": [
    "print(f'cell ranger total counts: {cr_cm.matrix.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "- Close enough -- 95% concordance.\n",
    "- I do not quite understand the difference; some thoughts:\n",
    "  - Duplicate marking is immaterial for 10x since we only count unique (CB, GE, UB) tuples.\n",
    "  - Multiple primary alignment is not an issue (unles CellRanger throws away reads with multiple primary alignments?)\n",
    "  - Filtering by MQ could be an issue (Optimus does not filter, CellRanger does, but it manipulates the STAR bam out such that it is difficult to interpret their downstream filter MQ == 255)\n",
    "  - Another source of discrepancy is the difference in barcode error correction\n",
    "  - A thorough reading of CellRanger code (WIP) is helpful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
